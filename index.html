<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="shortcut icon" href="favicon.ico" />
<link rel="bookmark" href="favicon.ico" type="image/x-icon"　/>
<title>Tao Sun (孙涛)</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Menu</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="https://scholar.google.com/citations?user=fPNZpAe5WXIC&hl=zh-CN">Google Scholar</a></div>
<div class="menu-item"><a href="https://www.researchgate.net/profile/Tao-Sun-75">ResearchGate</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Tao Sun (孙涛) </h1>
</div>
<table class="imgtable"><tr><td>
<a href="https://nudtsuntao1991.github.io/"><img src="photos/bio.webp" alt="alt text" width="131px" height="160px" /></a>&nbsp;</td>
<td align="left"><p>Associate   Professor（副研究员，硕导）,<br />
College of Computer Science and Technology, National University of Defense Technology （国防科技大学计算机学院）<br />
Changsha, Hunan, China <br /> 
<b>I am seeking self-motivated students with strong mathematical skills and/or programming expertise. If you are interested in optimization, please do not hesitate to contact me (没人呀,招人呐).<b> <br /> 
E-mail:<a href="mailto:suntao.saltfish@outlook.com">suntao.saltfish@outlook.com</a>;  <a href="mailto:nudtsuntao@163.com">nudtsuntao@163.com(Previous)</a></p>
</td></tr></table>
<h2>About me</h2>
<p>I am now an associate professor in a research group led by Prof. <a href="https://xinwangliu.github.io/"> Xinwang Liu</a>.</p>

<h2>News</h2>
<p> <b>Starting in September 2024, I will update the news section to collect the rejection experiences from my academic journey. </b></p>
<p>2025-05 Many papers were rejected by ICML. </p>
<p>2025-03 One paper was rejected by PAMI. </p>
<p>2025-02 Two papers were rejected by CVPR. </p>
<p>2025-01 Good month. No paper was rejected. </p>
<p>2024-12 One paper was rejected by JMLR. </p>
<p>2024-11 One paper was rejected by NC. </p>
<p>2024-10 Two papers were rejected by AAAI in the first round. </p>
<p>2024-9 One paper was rejected by NeurIPS, and another was withdrawn before. As a wise person once said, "As long as the withdrawal is done quickly, it won't be rejected." (no reference) </p>
<h2>Education</h2>
<p>Ph.D., Computational Mathematics, National University of Defense Technology, 12.2018</p>
<p>M.S., Computational Mathematics, National University of Defense Technology, 12.2014</p>
<p>B.S., Applied Mathematics,  National University of Defense Technology, 06.2012</p>
<h2>Experience</h2>
<p>Associate professor, National University of Defense Technology, 12.2022--Now</p>
<p>Assistant professor, National University of Defense Technology, 03.2019--12.2022</p>
<h2>Research</h2>
<p>My research interests include: </p>
<ul>
<li><p>Machine Learning  </p>
</li>
<li><p>Deep Learning</p>
</li>
<li><p>Optimization</p>
</li>
<li><p>Distributed Learning</p>
</li>
</ul>
<h3>Selected Conference Papers </h3>
<ol>
    <li><p> <b>T. Sun*</b>, Y. Huang, L. Shen, K. Xu, B. Wang, "Investigating the Role of Weight Decay in Enhancing Nonconvex SGD.", <i>CVPR</i>,  2025.</p> 
</li>
  <li><p> X. Deng**, <b>T. Sun*</b>,  et al., "Stability and Generalization of Asynchronous SGD: Sharper Bounds Beyond Lipschitz and Smoothness.", <i>NeurIPS</i>,  2024.</p> 
</li>
    <li><p> X. Pan, X. Li, J. Liu, <b>T. Sun</b>, K. Sun, L. Chen, Z. Qu, "Stability and Generalization for Stochastic Recursive Momentum-based Algorithms for (Strongly-) Convex One to K-Level Stochastic Optimizations.", <i>ICML</i>,  2024.</p> 
</li>
<li><p> X. Deng**, <b>T. Sun*</b>,  et al., "Exploring the Inefficiency of Heavy Ball as Momentum Parameter Approaches 1.", <i>IJCAI</i>,  2024.</p> 
</li>
<li><p> <b>T. Sun</b>,  et al., "Momentum Ensures Convergence of SIGNSGD under Weaker Assumptions.", <i>ICML</i>,  2023.</p> 
</li>
<li><p>X. Deng**, <b>T. Sun*</b>, S. Li,  et al.,  "Stability-Based Generalization Analysis of the Asynchronous Decentralized SGD.", <i>AAAI</i>,  2023.</p> 
</li>
<li><p><b>T. Sun</b>,  et al.,  "Finite-Time Analysis of Adaptive Temporal Difference Learning with Deep Neural Networks." <i>Advances in Neural Information Processing Systems<i>, 2022.</p>
</li>
<li><p><b>T. Sun</b>,  et al.,  "Adaptive Random Walk Gradient Descent for Decentralized Optimization." <i>International Conference on Machine Learning<i>, 2022.</p>
</li>
<li><p><b>T. Sun</b>,  et al.,  "Stability and Generalization of the Decentralized Stochastic Gradient Descent." <i>Proceedings of the AAAI Conference on Artificial Intelligence 35<i>, pp. 9756-9764 2021.</p>
</li>
<li><p><b>T. Sun</b>,  et al.,  "Heavy-ball Algorithms Always Escape Saddle Points". <i>Proceedings of the International Joint Conference on Artificial Intelligence<i>, pp.3520-3526, 2019. </p>
</li>
<li><p><b>T. Sun</b>, P. Yin, et al.,  "Non-ergodic Convergence Analysis of Heavy-ball Algorithms." <i>Proceedings of the AAAI Conference on Artificial Intelligence 33<i>, pp. 5033-5040, 2019.</p>
</li>
<li><p><b>T. Sun</b>, Y. Sun,  et al., "General Proximal Incremental Aggregated Gradient Algorithms: Better and Novel Results under General Scheme", <i>Advances in Neural Information Processing Systems 32</i>, 2019.</p>
</li>
<li><p>T. Chen, G. Giannakis, <b>T. Sun</b>,  W. Yin, "LAG: Lazily Aggregated Gradient for Communication-Efficient Distributed Learning.", <i>Advances in Neural Information Processing Systems 31</i>, 2018.</p>
</li>
<li><p><b>T. Sun</b>, Y. Sun, W. Yin, "On Markov Chain Gradient Descent", <i>Advances in Neural Information Processing Systems 31</i>, 2018.</p>
</li>
<li><p><b>T. Sun</b>, R. Hannah, W. Yin, "Asynchronous Coordinate Descent under More Realistic Assumptions", <i>Advances in Neural Information Processing Systems 30</i>, 2017.</p>
</li>
</ol>
<h3>Selected Journal Papers </h3>
<ol>
  <li><p>   <b>T. Sun</b>, L. Shen, X. Liu, "On Nonconvex SGD under Unbounded Noise with Weak Gradient Lipschitz and Delayed Stochastic Gradient", <i>IEEE Transactions on Pattern Analysis and Machine Intelligence </i>,  2025.</p> 
</li>
<li><p> S. Chen, X. Deng**, D. Xu*, <b>T. Sun*</b>,   et al., "Decentralized stochastic sharpness-aware minimization algorithm", <i>Neural Networks Journal</i>,  2024.</p> 
</li>
<li><p> <b>T. Sun</b>, Q. Wang, Y. Lei,  et al., "Pairwise Learning with Adaptive Online Gradient Descent", <i>Transactions on Machine Learning Research</i>,  2023.</p> 
</li>
<li><p> <b>T. Sun</b>,  et al., "On the Decentralized Stochastic Gradient Descent with Markov Chain Sampling", <i>IEEE Transactions on Signal Processing </i>,  2023.</p> 
</li>
<li><p> <b>T. Sun</b>,  et al., "Decentralized Federated Averaging.", <i>IEEE Transactions on Pattern Analysis and Machine Intelligence </i>,  2022.</p> 
</li>
<li><p> <b>T. Sun</b>,  et al., "General Nonconvex Total Variation and Low-Rank Regularizations: Model, Algorithm and Applications.", <i>Pattern  Recognition Journal </i>,  2022.</p> 
</li>
<li><p> <b>T. Sun</b>,  et al., "Sign Stochastic Gradient Descents without Bounded Gradient Assumption for the Finite Sum Minimization.", <i>Neural Networks Journal </i>,  2022.</p> 
</li>
<li><p>B. Wang#, T. M. Nguyen#, <b>T. Sun</b>#, A. L. Bertozzi, R. G. Baraniuk, S. J. Osher, "Scheduled Restart Momentum for Accelerated Stochastic Gradient Descent.", <i>SIAM J. Imaging Sciences </i>,  2021.</p>
</li>
<li><p><b>T. Sun</b>, H. Shen, T. Chen,  et al.,"Adaptive Temporal Difference Learning with Linear Function Approximation.", <i>IEEE Transactions on Pattern Analysis and Machine Intelligence </i>,  2021.</p>
</li>
<li><p><b>T. Sun</b>, L. Qiao, Q. Liao,  et al., "Novel Convergence Results of Adaptive Stochastic Gradient Descent.", <i>IEEE Transactions on Image Processing</i>,  2020.</p>
</li>
<li><p><b>T. Sun</b>, L. Qiao,  et al., "Non-ergodic Complexity of Proximal Inertial Gradient Descents.", <i>IEEE Transactions on Neural Networks and Learning Systems</i>,  2020.</p>
</li>
<li><p><b>T. Sun</b>, K. Tang,  et al., "Gradient Descent Learning with Floats.", <i>IEEE Transactions on Cybernetics</i>,  2020.</p>
</li>
<li><p><b>T. Sun</b>,  et al., "Capri: Consensus Accelerated Proximal Reweighted Iteration for A Class of Nonconvex Minimizations.", <i>IEEE Transactions on Knowledge and Data Engineering</i>,  2020.</p>
</li>
<li><p><b>T. Sun</b>, Y. Sun, Y. Xu, W. Yin, "Markov Chain Block Coordinate Descent.", <i> Computational Optimization and Applications</i>, pp. 35-61, 2020.</p>
</li>
<li><p><b>T. Sun</b>, R. Barrio, M. Rodriguez, H. Jiang, "Inertial Nonconvex Alternating Minimizations for the Image Deblurring.", <i> IEEE Transactions on Image Processing</i>, pp. 6211-6224, 2019.</p>
</li> 
<li><p><b>T. Sun</b>, P. Yin, H. Jiang, W. Zhu, "Iteratively Linearized Reweighted Alternating Direction Method of Multipliers for A Class of Nonconvex Problems.", <i>IEEE Transactions on Signal Processing</i>, pp.5380-5391, 2018.</p>
</li> 
<li><p><b>T. Sun</b>, P. Yin, H. Jiang, L. Cheng, "Alternating Direction Method of Multipliers with Difference of Convex Functions.", <i>Advances in Computational Mathematics</i>, pp.723-744, 2018.</p>
</li> 
<li><p><b>T. Sun</b>,  H. Jiang, L. Cheng, "Convergence of Proximal Iteratively Reweighted Nuclear Norm Algorithm for Image Processing.", <i>IEEE Transactions on Image Processing </i>, pp. 5632-5644, 2017.</p>
</li>
<li><p><b>T. Sun</b>,  H. Jiang, L. Cheng, "Global Convergence of Proximal Iteratively Reweighted Algorithm", <i>Journal of Global Optimization</i>, pp. 815-826, 2017.</p>
</li>
</ol>
<p><b>Note</b>: *indicates the corresponding author, # denotes equal contributions,** denotes my student.</p>
<p><a href="https://www.researchgate.net/profile/Tao-Sun-75">Full list of publications</a>.</p>
<h3>Academic service</h3>
<p><b>Editorial Board</b></p>
<ul>
   <li><p>Research, Science (Youth Editorial Board)</p>
</li>
  <li><p>Neural Networks, Elsevier</p>
</li>

</ul>
<p><b>Reviewer</b></p>
<ul>
<li><p>NeurIPS, ICML, ICLR, ECML, TMLR, AAAI, IJCAI, TPAMI</p>
</li>
</ul>
<p><b>Invited Talks</b></p>
<ul>
<li><p>2020 National Youth Forum on Computational Mathematics (2020 全国计算数学青年论坛)</p>
</li>
</ul>

  
  <h3>Others</h3>
  <p><b>Grants (Chinese)</b></p>
<ul>
<li><p>湖南省自然科学基金杰出青年科学基金 2022</p>
</li>
<li><p>中国科协青年托举，人工智能学会，科协资助，2022</p></li>
  <li><p>国自然面上、青年</p></li>
    <li>国防科大拔尖人才计划，2021</p></li>
      <li>JF项目两项</p></li>
</ul>
  

<p><b>Awards (Chinese)</b></p>
    <ul>
    <li><p>CCF优博提名奖2020</p></li>
<li><p>ACM中国新星奖（长沙分会,排名第一）,2023</p></li>
  <li><p>国防科大青年科技创新奖2023</p></li>
  <li><p>湖南省优秀博士论文奖2021</p></li>
</ul>

  
</td>
</tr>
</table>
</body>
</html>
